# Attention_in_Transformers


Summary of Learning
Concepts we are Learning

Transformer Encoder -	How it works and why it's used for understanding inputs
Positional Encoding -	How order is encoded using sine/cosine functions
Sentence Embedding -	How encoder transforms input into a fixed-length vector
Cosine Similarity -	How to compute similarity between two sentence vectors
PyTorch TransformerEncoder -	How to build a custom Transformer using PyTorch's encoder stack
